webpackJsonp([0xe91aa26c6993],{448:function(n,e){n.exports={data:{site:{siteMetadata:{title:"Ryan Oglesby"}},markdownRemark:{id:"/Users/ryanoglesby/Projects/blog/gatsby-blog/src/pages/homogeneous-pipelines-with-docker/index.md absPath of file >>> MarkdownRemark",html:'<p><a href="http://martinfowler.com/articles/continuousIntegration.html">Continuous Integration Build Pipelines</a>\nare a dirty, nasty place. What usually starts out as a couple of simple tasks or bash scripts\ninevitably ends up as a heap of scripts, Gradle/Rake/Maven/(insert build tool here) tasks, and\nmanually configured jobs held together with a thin layer of Elmer’s glue and Scotch tape.</p>\n<p>Why? Partly because modern applications are complex; even simple stacks use multiple languages and\ntools. And partly because developers are lazy, and sometimes hesitant to “mess with the pipeline.” I\ndon’t often see the amount of rigor in cleanliness applied to them as to other parts of the\ncodebase, leading to unnecessarily complex and unfortunately tangled build pipelines.</p>\n<p>So, my current team attacked this head-on using a great piece of technology:\n<a href="https://www.docker.com">Docker</a>! Using Docker as our sole interface to running things in our build\npipeline, we sped it up, simplified it, and lived happily ever after.</p>\n<p>To give credit where credit is due, the implementation of this pattern was spearheaded by my\ncolleague <a href="https://twitter.com/amber_ht">Amber Houle</a>.</p>\n<!-- more -->\n<h2>Anatomy of a Pipeline</h2>\n<p>This is pretty much what our build pipeline looked like in the time before Docker. Notice the amount\nof variation in what is being invoked in each step! (All these steps could be wrapped up in bash\nscripts, but I’ve unravelled them here.)</p>\n<p><em>“client” is a JS front-end application. “api” is a Java-based API.</em></p>\n<div class="gatsby-highlight">\n      <pre class="language-yaml"><code class="language-yaml"><span class="token comment"># pipeline.yaml</span>\n\n<span class="token key atrule">build_client</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> npm install       <span class="token comment"># Install JS dependencies</span>\n  <span class="token punctuation">-</span> npm run webpack   <span class="token comment"># Compile to JS</span>\n\n<span class="token key atrule">build_api</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> gradle build      <span class="token comment"># Compile Java</span>\n\n<span class="token key atrule">test_client</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> npm install       <span class="token comment"># Install JS dependencies..... again</span>\n  <span class="token punctuation">-</span> npm test          <span class="token comment"># Run JS tests</span>\n\n<span class="token key atrule">test_api</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> systemctl start postgresql.service  <span class="token comment"># Start up Postgres</span>\n  <span class="token punctuation">-</span> flyway migrate                      <span class="token comment"># Migrate the database using Flyway</span>\n  <span class="token punctuation">-</span> gradle test                         <span class="token comment"># Run Java tests (unit and integration)</span>\n  <span class="token punctuation">-</span> systemctl stop postgresql.service   <span class="token comment"># Stop Postgres</span>\n\n<span class="token key atrule">package_client</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> npm install       <span class="token comment"># Install JS dependencies once again :(</span>\n  <span class="token punctuation">-</span> npm run package   <span class="token comment"># Package up the JS into a .zip or .tar</span>\n  <span class="token punctuation">-</span> &lt;push JS code to artifact repository<span class="token punctuation">></span>\n\n<span class="token key atrule">package_api</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> gradle package    <span class="token comment"># Create an executable .jar</span>\n  <span class="token punctuation">-</span> &lt;push Java code to artifact repository<span class="token punctuation">></span>\n\n<span class="token key atrule">deploy_to_qa</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> &lt;pull code from artifact repo and deploy<span class="token punctuation">></span>\n</code></pre>\n      </div>\n<p>Let’s first examine a build pipeline that you might find using any of the modern open-source\ndistributed build and deploy tools such as <a href="https://jenkins.io/">Jenkins</a>,\n<a href="https://www.go.cd/">Go.cd</a>, or <a href="https://travis-ci.com/">TravisCI</a>. It’s broken down into a series\nof stages or jobs, which could be run sequentially or in parallel. Because these tools usually run\nas a <a href="https://jenkins.io/doc/book/architecting-for-scale/">master/agent architecture</a>, the server\nwill delegate the actual work of each stage to an available build agent.</p>\n<h3>Pipeline complexities</h3>\n<p>While this architecture is scalable and flexible, it creates complexities that <strong>you</strong> have to\nmanage. Since each stage in your pipeline has a different job to do, all your agents must be\nconfigured to perform all needed actions. Some stages need a JavaScript runtime, some need Java,\nwhile others need a Postgres database. Traditionally, this calls for provisioning your agents with\nall the appropriate software ahead of time. And herein lies a dilemma. Manually provisioning might\nwork fine if you only have 1 or 2 agents, but that quickly becomes tedious as the number of\ndependencies you have increases or the number of agents you need increases. Automated provisioning\nusing Chef or Puppet is an option, but this creates one more piece of code to build, manage, test,\nand debug.</p>\n<p>As each agent picks up a stage to run, it’s going to need some input, which is often just a copy of\nyour source code at a specific revision. Because any agent could be picking up any job at any time,\nthe sequence is usually 1) start with a clean workspace 2) checkout the code 3) install\ndependencies 4) do stuff. All these steps take time, especially installing dependencies. (There are\n3 <code>npm install</code> commands in the pipeline shown above)</p>\n<h2>Docker as the Pipeline Interface</h2>\n<blockquote>\n<p>Docker containers wrap a piece of software in a complete filesystem that contains everything\nneeded to run: code, runtime, system tools, system libraries – anything that can be installed on a\nserver. <br/> <cite><a href="https://www.docker.com/what-docker">https://www.docker.com/what-docker</a></cite></p>\n</blockquote>\n<p>What if we extend this statement to say that containers contain everything needed to run… <strong>and\nbuild and test</strong>? Instead of provisioning build agents with all the individual pieces of software\nand dependencies that our pipeline needs, let’s provision them with only the Docker Engine. Now, the\nsequence of steps for any stage becomes 1) Pull down a Docker image 2) Execute <code>docker run</code>\n<a href="https://docs.docker.com/engine/reference/run/">https://docs.docker.com/engine/reference/run/</a>.</p>\n<p>To pull this off, we first need to create some Docker images with <strong>everything our application needs\nto build and test itself</strong>, which we specify with a\n<a href="https://docs.docker.com/engine/reference/builder/">Dockerfile</a>.</p>\n<div class="gatsby-highlight">\n      <pre class="language-docker"><code class="language-docker"><span class="token comment"># Dockerfile for Java API</span>\n\n<span class="token keyword">FROM</span> java<span class="token punctuation">:</span>8\n\n<span class="token keyword">COPY</span> build.gradle ./\n<span class="token keyword">COPY</span> src ./src/\n\n<span class="token keyword">RUN</span> gradle jar\n\n<span class="token keyword">ENTRYPOINT</span> <span class="token punctuation">[</span><span class="token string">"gradle"</span><span class="token punctuation">]</span>\n</code></pre>\n      </div>\n<div class="gatsby-highlight">\n      <pre class="language-docker"><code class="language-docker"><span class="token comment"># Dockerfile for database migrations</span>\n\n<span class="token keyword">FROM</span> shouldbee/flyway\n\n<span class="token keyword">COPY</span> ./src/main/resources/db/migration/*.sql ./sql/\n\n<span class="token keyword">ENTRYPOINT</span> <span class="token punctuation">[</span><span class="token string">"flyway"</span><span class="token punctuation">]</span>\n</code></pre>\n      </div>\n<div class="gatsby-highlight">\n      <pre class="language-docker"><code class="language-docker"><span class="token comment"># Dockerfile for JS client</span>\n\n<span class="token keyword">FROM</span> node<span class="token punctuation">:</span>6.4.0\n\n<span class="token keyword">COPY</span> package.json ./\n<span class="token keyword">RUN</span> npm install\n<span class="token keyword">COPY</span> src ./src/\n<span class="token keyword">RUN</span> npm run webpack\n\n<span class="token keyword">ENTRYPOINT</span> <span class="token punctuation">[</span> <span class="token string">"npm"</span><span class="token punctuation">,</span> <span class="token string">"run"</span> <span class="token punctuation">]</span>\n</code></pre>\n      </div>\n<p>And this is pretty much what our pipeline evolved into after transitioning to Docker…</p>\n<div class="gatsby-highlight">\n      <pre class="language-yaml"><code class="language-yaml"><span class="token comment"># pipeline.yaml</span>\n\n<span class="token key atrule">build_client</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> docker build <span class="token punctuation">-</span>t client<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span> ./client  <span class="token comment"># Build Docker image</span>\n  <span class="token punctuation">-</span> docker push client<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span>               <span class="token comment"># Push it to the container registry</span>\n\n<span class="token key atrule">build_api</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> docker build <span class="token punctuation">-</span>t api<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span> ./api\n  <span class="token punctuation">-</span> docker build <span class="token punctuation">-</span>t migrations<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span> ./api\n\n  <span class="token punctuation">-</span> docker push api<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span>\n  <span class="token punctuation">-</span> docker push migrations<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span>\n\n<span class="token key atrule">test_client</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> docker pull client<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span>\n  <span class="token punctuation">-</span> docker run client<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span> test   <span class="token comment"># Run `npm run test` inside of the client container</span>\n\n<span class="token key atrule">test_api</span><span class="token punctuation">:</span>\n  <span class="token punctuation">-</span> docker pull api<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span>\n  <span class="token punctuation">-</span> docker pull migrations<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span>\n\n  <span class="token punctuation">-</span> docker run migrations<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span> migrate  <span class="token comment"># Run `flyway migrate` inside of the migrations container</span>\n  <span class="token punctuation">-</span> docker run api<span class="token punctuation">:</span>$<span class="token punctuation">{</span>PIPELINE_ID<span class="token punctuation">}</span> test            <span class="token comment"># Run `gradle test` inside of the api container</span>\n</code></pre>\n      </div>\n<h3>Complexities simplified</h3>\n<p>Overall, this had a number of positive effects on our build pipeline. First, <strong>speed</strong>: the time\nfrom pipeline start to ready to deploy to a QA environment dropped from ~12 minutes to ~4 minutes!\nThis was largely due to no longer checking out the entire code base, installing dependencies, and\nre-compiling in each step of the pipeline. Second, <strong>simplicity.</strong> Configuring new build agents is\nnow easy, as they only need Docker Engine. The single command interface is also cognitively simple.\nEach call to <code>docker run [COMMAND]</code> in the pipeline acts as a proxy to the task runner already in\nuse in the codebase (e.g <code>gradle [COMMAND]</code> or <code>npm run [COMMAND]</code>), making it work just like local\ndevelopment without Docker.</p>\n<p>The main possible issue I see with this is that the Docker container has a large surface area, which\nkind of goes against the advice from Docker to keep images as slim and trim as possible. I normally\nwould not include all my test code into the deployable artifact that will eventually end up on my\nproduction server. Instead we have copied <strong>all</strong> the source and test code into the image. This\ncould introduce dependency issues, such as security holes that may exist in libraries pulled in by\ntest code. I have not observed this in practice though.</p>\n<p>You will also notice that we push the Docker image to the registry right away. This ensures that the\nartifact that passes down the pipeline is exactly the same all the way through build, test, and\ndeploy. But, it also means we are creating an artifact for un-verified code. What if the tests fail\nfor a certain commit, but we have already created and pushed the Docker image? Do we leave it in the\nregistry? Remove it? So far, we have just left them there, so not sure how this will play out in the\nlong term.</p>\n<p>Overall, this pattern has worked well for the team! Would love to hear your opinions and experiences\nwith Docker in a build pipeline.</p>',frontmatter:{title:"Homogeneous Pipelines with Docker",date:"September 26, 2016"}}},pathContext:{slug:"/homogeneous-pipelines-with-docker/",previous:{fields:{slug:"/how-your-mother-can-help-you-build-cleaner-unit-tests/part-iii/"},frontmatter:{title:"How your 'Mother' can help you 'Build' cleaner unit tests - Part III"}},next:{fields:{slug:"/harmonious-stylesheets-and-inline-styles-in-react/"},frontmatter:{title:"Harmonious Stylesheets and Inline Styles in React"}}}}}});
//# sourceMappingURL=path---homogeneous-pipelines-with-docker-a8c9cdc622ab1e435c4f.js.map